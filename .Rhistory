y ~.,
data = train,
method = "under",  # under or over
seed = 4321
)$data %>%
setDT()  %>%
.[, y := factor(y, levels = c("yes", "no"))]
# logistic regression again ===================================================
lr <- glm(y ~ ., data = train_un, family = binomial)
lr_pred_train <- predict(lr, train, type = "response")
lr_roc_train <- roc(train$y, lr_pred_train)
lr_pred_test <- predict(lr, test, type = "response")
lr_roc_test <- roc(test$y, lr_pred_test)
# plot roc curves using train and test data
plot_rocs(`logit train` = lr_roc_train, `logit test` = lr_roc_test)
plot_lifts(test$y, logit_test = 1 - lr_pred_test)
# random forest model ==========================================================
# train_control <- trainControl(
#     method = "cv",
#     number = 5,
#     search = "random",
#     classProbs = TRUE,  # for metric = "ROC"
#     summaryFunction=twoClassSummary,  # for metric "ROC"
#     verboseIter = FALSE
# )
#
# tune_grid <- expand.grid(mtry = 5:7)
#
# use a subset of train_un to quickly find the optimal max_node of random forest
# turns out AUC is not sensitive to max_node. Select 32 to reduce computation
# load.
# set.seed(1111)
# for (max_nodes in 2^(2:10)){
#     cat(paste0("\nmaxnodes = ", max_nodes, ":\n"))
#
#     rf <- train(
#         y ~.,
#         data = train_un[sample(1:nrow(train_un), 5000)],
#         method = "rf",
#         maxnodes = max_nodes,
#         metric = "ROC",
#         trControl = train_control,
#         tuneGrid = tune_grid
#     )
#
#     print(rf$results)
# }
# use the max_node to train a random forest model
rf <- randomForest(y ~ ., train_un,
maxnodes = 32,
ntree = 1000)
rf_pred_train <- predict(rf, train, type = "prob")[, "yes"]
rf_roc_train <- roc(train$y, rf_pred_train)
rf_pred_test <- predict(rf, test, type = "prob")[, "yes"]
rf_roc_test <- roc(test$y, rf_pred_test)
plot_rocs(`rf train` = rf_roc_train, `rf test` = rf_roc_test)
plot_lifts(test$y, rf_test = rf_pred_test)
# xgboost ======================================================================
train_control <- trainControl(
method = "cv",
number = 5,
search = "random",
classProbs = TRUE,  # for metric = "ROC"
summaryFunction=twoClassSummary,  # for metric "ROC"
verboseIter = TRUE
)
xgb <- train(
y ~.,
data = train_un,
method = "xgbTree",
#weights = ifelse(dat_train$y == "no", 0.1, 0.9),
metric = "ROC",
trControl = train_control,
tuneLength = 100
)
xgb_pred_train <- predict(xgb, train, type = "prob")[, "yes"]
xgb_roc_train <- roc(train$y, xgb_pred_train)
xgb_pred_test <- predict(xgb, test, type = "prob")[, "yes"]
xgb_roc_test <- roc(test$y, xgb_pred_test)
plot_rocs(`xgb train` = xgb_roc_train, `xgb test` = xgb_roc_test)
plot_lifts(test$y, xgb_test = xgb_pred_test)
# compare ======================================================================
plot_rocs(base = base_roc_test,
logistic_regression = lr_roc_test,
random_forest = rf_roc_test,
xgb_test = xgb_roc_test)
plot_lifts(test$y,
base = 1 - base_pred_test,
logistic_regression = 1 - lr_pred_test,
random_forest = rf_pred_test,
xgb = xgb_pred_test)
?save
save(train, test, train_un, base, lr, rf, xgb, file = "model_20200609.RData")
train_un
# support vector machine ======================================================
svm <- svm(y ~ ., data = train_un)
svm_pred_train <- predict(svm, train, type = "response")
svm_pred_train
svm_pred_train <- predict(svm, train)
svm_pred_train
svm_pred_train <- predict(svm, train, type = "prob")
svm_pred_train
?svm
# support vector machine ======================================================
svm <- svm(y ~ ., data = train_un, probability = TRUE)
svm_pred_train <- predict(svm, train, probability = TRUE)
svm_pred_train
svm_pred_train <- predict(svm, train, probability = TRUE)[, "yes"]
svm_pred_train[, "yes"]
str(svm_pred_train)
class(svm_pred_train)
svm_pred_train
svm_pred_train -> aaa
attr(aaa, "probability")
attr(aaa, "probabilities")
attr(aaa, "probabilities")[, "yes"]
svm_pred_train <- predict(svm, train, probability = TRUE) %>%
attr("probabilities")[, "yes"]
attr(aaa, "probabilities")[, "yes"]
attr(aaa, "probabilities")[, "yes"]
?attr
svm_pred_train <- predict(svm, train, probability = TRUE) %>%
attr(svm_pred_train, "probabilities")[, "yes"]
attr(svm_pred_train, "probabilities")[, "yes"]
svm_pred_train <- predict(svm, train, probability = TRUE)
svm_pred_train <-    attr(svm_pred_train, "probabilities")[, "yes"]
svm_roc_train <- roc(train$y, svm_pred_train)
svm_pred_test <- predict(svm, test, probability = TRUE)
svm_pred_test <- attr(svm_pred_test, "probabilities")[, "yes"]
svm_roc_test <- roc(test$y, svm_pred_test)
# plot roc curves using train and test data
plot_rocs(`svm train` = svm_roc_train, `svm test` = svm_roc_test)
plot_lifts(test$y, svm_test = 1 - svm_pred_test)
plot_lifts(test$y, svm_test = svm_pred_test)
train_control <- trainControl(
method = "cv",
number = 5,
search = "random",
classProbs = TRUE,  # for metric = "ROC"
summaryFunction=twoClassSummary,  # for metric "ROC"
verboseIter = TRUE
)
svm <- train(
y ~.,
data = train_un,
method = "svmRadial",
metric = "ROC",
trControl = train_control,
tuneLength = 10
)
train_control <- trainControl(
method = "cv",
number = 3,
search = "random",
classProbs = TRUE,  # for metric = "ROC"
summaryFunction=twoClassSummary,  # for metric "ROC"
verboseIter = TRUE
)
svm <- train(
y ~.,
data = train_un,
method = "svmRadial",
metric = "ROC",
trControl = train_control,
tuneLength = 3
)
svm_pred_train <- predict(svm, train, probability = TRUE)
svm_pred_train
svm <- train(
y ~.,
data = train_un,
method = "svmRadial",
probabilities = TRUE,
metric = "ROC",
trControl = train_control,
tuneLength = 1
)
svm$results
svm_pred_train <- predict(svm, train, probability = TRUE)
svm_pred_train
svm_pred_test <- predict(svm, test, type = "prob")
svm_pred_test
svm_pred_test <- predict(svm, test, type = "prob")[, "yes"]
svm_roc_test <- roc(test$y, svm_pred_test)
svm_pred_train <- predict(svm, train, type = "prob")[, "yes"]
#svm_pred_train <-    attr(svm_pred_train, "probabilities")[, "yes"]
svm_roc_train <- roc(train$y, svm_pred_train)
# plot roc curves using train and test data
plot_rocs(`svm train` = svm_roc_train, `svm test` = svm_roc_test)
svm$results
train_control <- trainControl(
method = "cv",
number = 5,
search = "random",
classProbs = TRUE,  # for metric = "ROC"
summaryFunction=twoClassSummary,  # for metric "ROC"
verboseIter = TRUE
)
svm <- train(
y ~.,
data = train_un,
method = "svmRadial",
probabilities = TRUE,
metric = "ROC",
trControl = train_control,
tuneLength = 20
)
plot(svm)
svm_pred_train <- predict(svm, train, type = "prob")[, "yes"]
#svm_pred_train <-    attr(svm_pred_train, "probabilities")[, "yes"]
svm_roc_train <- roc(train$y, svm_pred_train)
svm_pred_test <- predict(svm, test, type = "prob")[, "yes"]
#svm_pred_test <- attr(svm_pred_test, "probabilities")[, "yes"]
svm_roc_test <- roc(test$y, svm_pred_test)
# plot roc curves using train and test data
plot_rocs(`svm train` = svm_roc_train, `svm test` = svm_roc_test)
aaa = plot(1:3, 1:3)
aaa
# plot roc curves using train and test data
svm_roc <- plot_rocs(`svm train` = svm_roc_train, `svm test` = svm_roc_test)
svm_roc
class(svm_roc)
svm_lift <- plot_lifts(test$y, svm_test = svm_pred_test)
svm_lift
# compare ======================================================================
all_rocs <- plot_rocs(base = base_roc_test,
logistic_regression = lr_roc_test,
svm = svm_roc_test,
random_forest = rf_roc_test,
xgb_test = xgb_roc_test)
all_rocs
all_lifts <- plot_lifts(test$y,
base = 1 - base_pred_test,
logistic_regression = 1 - lr_pred_test,
svm =
random_forest = rf_pred_test,
xgb = xgb_pred_test)
all_lifts <- plot_lifts(test$y,
base = 1 - base_pred_test,
logistic_regression = 1 - lr_pred_test,
svm = svm_pred_test,
random_forest = rf_pred_test,
xgb = xgb_pred_test)
all_lifts
source('~/Dropbox/jobs/2020/beyond-phone-interview/quicken-loans/QL-case-study/utilities.R')
# plot roc curves using train and test data
base_roc <- plot_rocs(`base train` = base_roc_train, `base test` = base_roc_test)
base_roc
base_lift <- plot_lifts(y = dat_test$y, base_test = 1 - base_pred_test)
base_lift
# plot roc curves using train and test data
lr_roc <- plot_rocs(`logit train` = lr_roc_train, `logit test` = lr_roc_test)
lr_roc
lr_lift <- plot_lifts(test$y, logit_test = 1 - lr_pred_test)
lr_lift
# plot roc curves using train and test data
svm_roc <- plot_rocs(`svm train` = svm_roc_train, `svm test` = svm_roc_test)
svm_roc
svm_lift <- plot_lifts(test$y, svm_test = svm_pred_test)
svm_lift
rf_roc <- plot_rocs(`rf train` = rf_roc_train, `rf test` = rf_roc_test)
rf_roc
rf_lift <- plot_lifts(test$y, rf_test = rf_pred_test)
rf_lift
xgb_roc <- plot_rocs(`xgb train` = xgb_roc_train, `xgb test` = xgb_roc_test)
xgb_roc
xgb_lift <- plot_lifts(test$y, xgb_test = xgb_pred_test)
knitr::opts_chunk$set(echo = TRUE)
plot_avg(dat, "month") +
labs(x = "Month", y = "Average Success Rate")
dat <- fread("bank/bank-full.csv") %>%
.[y == "yes", y := 1] %>%
.[y == "no", y := 0] %>%
.[, y := as.integer(y)]
plot_avg(dat, "month") +
labs(x = "Month", y = "Average Success Rate")
dat$month = factor(dat$month,
levels = c("jan", "feb", "mar", "apr", "may", "jun", "jul",
"aug", "sep", "oct", "nov", "dec"))
plot_avg(dat, "month") +
labs(x = "Month", y = "Average Success Rate")
# all ROC using test data
all_rocs <- plot_rocs(base = base_roc_test,
logistic_regression = lr_roc_test,
svm = svm_roc_test,
random_forest = rf_roc_test,
xgb = xgb_roc_test)
all_rocs
# all LIFT curves using test data
all_lifts <- plot_lifts(test$y,
base = 1 - base_pred_test,
logistic_regression = 1 - lr_pred_test,
svm = svm_pred_test,
random_forest = rf_pred_test,
xgb = xgb_pred_test)
# moving average
moving_avg <- function(x, n){
ts <- stats::filter(x = x, filter = rep(1, n)/n, sides = 1)
as.vector(ts)
}
dat[, mv_avg := moving_avg(y, 100)]
plot(1:nrow(dat), dat$mv_avg, type = "l",
main = "Moving Avarage of Sucess Rate (n = 100)",
xlab = "Sample (Row) Index",
ylab = "Average Success Rate")
all_lifts
# save data, models, and plots
save(train, test, train_un,
base, lr, svm, rf, xgb,
all_rocs, all_lifts,
base_roc, base_lift,
lr_roc, lr_lift,
svm_roc, wvm_lift,
rf_roc, rf_lift,
xgb_roc, xgb_lift,
file = "model_20200610.RData")
# save data, models, and plots
save(train, test, train_un,
base, lr, svm, rf, xgb,
all_rocs, all_lifts,
base_roc, base_lift,
lr_roc, lr_lift,
svm_roc, svm_lift,
rf_roc, rf_lift,
xgb_roc, xgb_lift,
file = "model_20200610.RData")
# select xgb as the final model
xgb_base_roc <- plot_rocs(base = base_roc_test,
xgb = xgb_roc_test)
xgb_base_roc
xgb_base_lift <- plot_lifts(test$y,
base = 1 - base_pred_test,
xgb = xgb_pred_test)
xgb_base_lift
?ggsave
ggsave("xgb_base_lift.png", xgb_base_lift)
ggsave("xgb_base_lift.png", xgb_base_lift, width = 5, height = 4)
ggsave("xgb_base_lift.png", xgb_base_lift, width = 5.5, height = 4)
all_rocs
ggsave("all_rocs.png", all_rocs, width = 5.5, height = 4)
ggsave("all_lifts.png", all_lifts, width = 5.5, height = 4)
xgb_lift$data
xgb_lift$data -> aaa
View(aaa)
names(xgb_lift)
xgb_lift$coordinates
names(xgb_lift)
xgb_lift$layers
xgb_lift$layers -> aaa
aaa = ggplot_build(xgb_lift)
names(aaa)
bbb = aaa$data
bbb
bbb[[1]]
bbb[[1]] -> ccc
ccc
View(ccc)
ggsave("base_roc.png", base_roc, width = 5.5, height = 4)
ggsave("base_lift.png", base_lifts, width = 5.5, height = 4)
ggsave("base_lift.png", base_lift, width = 5.5, height = 4)
dat_train$balance
hist(dat_train$balance)
hist(dat_train$balance, breaks = 100)
hist(train$balance, breaks = 100)
hist(train$balance, breaks = 100, xlim = c(-10, 10))
dat
mean(dat$y)
dat[, mv_avg := moving_avg(y, 100)]
plot(1:nrow(dat), dat$mv_avg, type = "l",
main = "Moving Avarage of Sucess Rate (n = 100)",
xlab = "Sample (Row) Index",
ylab = "Average Success Rate")
knitr::opts_chunk$set(echo = TRUE)
source("utilities.R")
dat <- fread("bank/bank-full.csv") %>%
.[y == "yes", y := 1] %>%
.[y == "no", y := 0] %>%
.[, y := as.integer(y)]
```{r}
barplot(table(dat$y), ylab = "Count")
# moving average
moving_avg <- function(x, n){
ts <- stats::filter(x = x, filter = rep(1, n)/n, sides = 1)
as.vector(ts)
}
dat[, mv_avg := moving_avg(y, 100)]
plot(1:nrow(dat), dat$mv_avg, type = "l",
main = "Moving Avarage of Sucess Rate (n = 100)",
xlab = "Sample (Row) Index",
ylab = "Average Success Rate")
hist(dat$age, breaks = 100)
288/54211
plot_avg(dat, "age")
plot_avg(dat, "job") + theme(axis.text.x = element_text(angle = 20, hjust = 1))
plot_avg(dat, "marital")
1857/54211
plot_avg(dat, "default")
hist(dat$balance, breaks = 100)
dat$balance_cut <- ggplot2::cut_number(dat$balance, n = 5)
plot_avg(dat, "balance_cut")
plot_avg(dat, "housing")
plot_avg(dat, "loan")
plot_avg(dat, "contact")
322/54211
plot_avg(dat, "day")
barplot(table(dat$campaign))
plot_avg(dat, "campaign")
hist(dat$pdays, breaks = 100)
plot_avg(dat, "pdays")
plot_avg(dat, "pdays") + xlim(0, 30)
plot_avg(dat, "pdays")
plot_avg(dat, "pdays") + xlim(0, 30)
plot_avg(dat, "previous") + xlim(0, 40)
plot_avg(dat, "poutcome")
source("utilities.R")
library(randomForest)
library(xgboost)
library(e1071)
library(pROC)     # plot ROC
library(ROSE)     # for undersampling
# read data and split into train and test =====================================
# remember to remove duration, month, and day
dat <- fread("bank/bank-full.csv",
stringsAsFactors = TRUE) %>%
.[, y := factor(y, levels = c("yes", "no"))] %>%
.[, duration := NULL] %>%
.[, month := NULL] %>%
.[, day := NULL]
# random train-test split instead of based on time.
set.seed(98765)
in_train <- createDataPartition(dat$y, p = 0.7, list = F)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
base <- glm(y ~ ., data = dat_train, family = binomial)
base_pred_train <- predict(base, dat_train, type = "response")
base_roc_train <- roc(dat_train$y, base_pred_train)
base_pred_test <- predict(base, dat_test, type = "response")
base_roc_test <- roc(dat_test$y, base_pred_test)
# plot roc curves using train and test data
base_roc <- plot_rocs(`base train` = base_roc_train, `base test` = base_roc_test)
base_roc
add_feature <- function(data = dat_train){
# pdays into categorical feature pcontact of two groups
data[, previous_contact := factor(ifelse(pdays == -1, "no", "yes"))]
return(data)
}
dat_train <- add_feature(dat_train)
dat_test <- add_feature(dat_test)
# fix skewness
fix_skewness <- preProcess(dat_train, method = c("center", "scale", "YeoJohnson"))
train <- predict(fix_skewness, dat_train)
test <- predict(fix_skewness, dat_test)
# over-sampling train data
train_un <- ovun.sample(
y ~.,
data = train,
method = "under",  # under or over
seed = 4321
)$data %>%
setDT()  %>%
.[, y := factor(y, levels = c("yes", "no"))]
lr <- glm(y ~ ., data = train_un, family = binomial)
lr_pred_train <- predict(lr, train, type = "response")
lr_roc_train <- roc(train$y, lr_pred_train)
lr_pred_test <- predict(lr, test, type = "response")
lr_roc_test <- roc(test$y, lr_pred_test)
# plot roc curves using train and test data
lr_roc <- plot_rocs(`logit train` = lr_roc_train, `logit test` = lr_roc_test)
lr_roc
# use the max_node = 32 to train a random forest model
rf <- randomForest(y ~ ., train_un,
maxnodes = 32,
ntree = 1000)
rf_pred_train <- predict(rf, train, type = "prob")[, "yes"]
rf_roc_train <- roc(train$y, rf_pred_train)
rf_pred_test <- predict(rf, test, type = "prob")[, "yes"]
rf_roc_test <- roc(test$y, rf_pred_test)
# plot roc and lift curves
rf_roc <- plot_rocs(`rf train` = rf_roc_train, `rf test` = rf_roc_test)
rf_roc
?glm
knitr::opts_chunk$set(echo = TRUE)
source("utilities.R")
source("utilities.R")
dat <- fread("bank/bank-full.csv") %>%
.[y == "yes", y := 1] %>%
.[y == "no", y := 0] %>%
.[, y := as.integer(y)]
View(dat)
?getDTthreads
dat <- fread("bank/bank-full.csv") %>%
.[, y:= ifelse(y == "yes", 1, 0)]
barplot(table(dat$y), ylab = "Count")
# moving average
moving_avg <- function(x, n){
ts <- stats::filter(x = x, filter = rep(1, n)/n, sides = 1)
as.vector(ts)
}
dat[, mv_avg := moving_avg(y, 100)]
plot(1:nrow(dat), dat$mv_avg, type = "l",
main = "Moving Avarage of Sucess Rate (n = 100)",
xlab = "Sample (Row) Index",
ylab = "Average Success Rate")
hist(dat$age, breaks = 100)
plot_avg(dat, "age")
plot_avg(dat, "job") + theme(axis.text.x = element_text(angle = 20, hjust = 1))
plot_avg(dat, "marital")
plot_avg(dat, "education") + theme(axis.text.x = element_text(angle = 20, hjust = 1))
plot_avg(dat, "default")
hist(dat$balance, breaks = 100)
dat$balance_cut <- ggplot2::cut_number(dat$balance, n = 5)
plot_avg(dat, "balance_cut")
