summary(lr)
# read data, remove duration
dat <- read.csv("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE,
sep = ";")
dat$duration <- NULL
# train-test split
set.seed(1234)
in_train <- caret::createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
# baseline model: logistic regression
lr <- glm(y ~ ., data = dat_train, family = binomial)
lr_pred_train <- predict(lr, dat_train, type = "response")
lr_roc_train <- roc(dat_train$y, lr_pred_train)
lr_pred_test <- predict(lr, dat_test, type = "response")
lr_roc_test <- roc(dat_test$y, lr_pred_test)
# plot roc curves using train and test data
plot_rocs(`logit train` = lr_roc_train, `logit test` = lr_roc_test)
summary(lr)
# read data and split into train and test =====================================
# remember to remove duration
dat <- fread("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE) %>%
.[, duration := NULL]
set.seed(1234)
in_train <- createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
treat_cat <- function(data = dat_train){
# To treat categorical feature. The unknowns are treated as its own category
# as there are reasons to be missing.
#
# Arguments
# ---------
#   data: data frame with features to be preprocessed
#
# Return
# ------
#   A data frame with preproccessed features
# "unknown" and "yes" in "default combined as one group as only 3 "yes"
data[default %in% c("unknown", "yes"), default := "TBD"]
# create a new categorical feature for those age > 60
data[age > 60, over_60 := "yes"]
data[age <= 60, over_60 := "no"]
data[, over_60 := factor(over_60)]
# pdays into categorical feature pcontact of two groups
data[pdays == 999, pcontact := "no"]
data[pdays != 999, pcontact := "yes"]
data[, pcontact := factor(pcontact) ]
data[, pdays := NULL]
# loan not important
data[, loan := NULL]
return(data)
}
treat_num <- function(data_train, data_new = NULL){
# fix skewness
if (is.null(data_new)){
data_new <- data_train
}
preproc <- preProcess(data_train, method = c("BoxCox"))
data_new <- predict(preproc, data_new)
# remove not important features
data_new[, cons.conf.idx := NULL]
data_new[, nr.employed := NULL]
return(data_new)
}
dat_train <- treat_cat(dat_train)
dat_train <- treat_num(dat_train)
dat_test <- treat_cat(dat_test)
dat_test <- treat_num(dat_train, dat_test)
# logistic regression again ===================================================
lr <- glm(y ~ ., data = dat_train, family = binomial)
lr_pred_train <- predict(lr, dat_train, type = "response")
lr_roc_train <- roc(dat_train$y, lr_pred_train)
lr_pred_test <- predict(lr, dat_test, type = "response")
lr_roc_test <- roc(dat_test$y, lr_pred_test)
# plot roc curves using train and test data
plot_rocs(`logit train` = lr_roc_train, `logit test` = lr_roc_test)
# over-sampling train data
dat_train <- ovun.sample(
y ~.,
data = dat_train,
method = "over",
seed = 4321
)$data
# logistic regression again ===================================================
lr <- glm(y ~ ., data = dat_train, family = binomial)
lr_pred_train <- predict(lr, dat_train, type = "response")
lr_roc_train <- roc(dat_train$y, lr_pred_train)
lr_pred_test <- predict(lr, dat_test, type = "response")
lr_roc_test <- roc(dat_test$y, lr_pred_test)
# plot roc curves using train and test data
plot_rocs(`logit train` = lr_roc_train, `logit test` = lr_roc_test)
# random forest model =================================================
rf <- randomForest(y ~ ., dat_train)
library(randomForest)
# random forest model =================================================
rf <- randomForest(y ~ ., dat_train)
rf_pred_train <- predict(rf, dat_train, type = "prob")[2]
rf_roc_train <- roc(dat_train$y, rf_pred_train)
rf_pred_test <- predict(rf, dat_test, type = "prob")[2]
rf_roc_test <- roc(dat_test$y, rf_pred_test)
rf_pred_train <- predict(rf, dat_train, type = "prob")[, 2]
rf_roc_train <- roc(dat_train$y, rf_pred_train)
rf_pred_test <- predict(rf, dat_test, type = "prob")[, 2]
rf_roc_test <- roc(dat_test$y, rf_pred_test)
plot_rocs(`rf train` = rf_roc_train, `rf test` = rf_roc_test)
# read data and split into train and test =====================================
# remember to remove duration
dat <- fread("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE) %>%
.[, duration := NULL]
set.seed(1234)
in_train <- createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
treat_cat <- function(data = dat_train){
# To treat categorical feature. The unknowns are treated as its own category
# as there are reasons to be missing.
#
# Arguments
# ---------
#   data: data frame with features to be preprocessed
#
# Return
# ------
#   A data frame with preproccessed features
# "unknown" and "yes" in "default combined as one group as only 3 "yes"
data[default %in% c("unknown", "yes"), default := "TBD"]
# create a new categorical feature for those age > 60
data[age > 60, over_60 := "yes"]
data[age <= 60, over_60 := "no"]
data[, over_60 := factor(over_60)]
# pdays into categorical feature pcontact of two groups
data[pdays == 999, pcontact := "no"]
data[pdays != 999, pcontact := "yes"]
data[, pcontact := factor(pcontact) ]
data[, pdays := NULL]
# loan not important
data[, loan := NULL]
return(data)
}
treat_num <- function(data_train, data_new = NULL){
# fix skewness
if (is.null(data_new)){
data_new <- data_train
}
preproc <- preProcess(data_train, method = c("BoxCox"))
data_new <- predict(preproc, data_new)
# remove not important features
data_new[, cons.conf.idx := NULL]
data_new[, nr.employed := NULL]
return(data_new)
}
dat_train <- treat_cat(dat_train)
dat_train <- treat_num(dat_train)
dat_test <- treat_cat(dat_test)
dat_test <- treat_num(dat_train, dat_test)
# over-sampling train data
dat_train <- ovun.sample(
y ~.,
data = dat_train,
method = "over",
seed = 4321
)$data
library(data.table)
library(magrittr)
library(caret)
library(randomForest)
library(RANN)     # for knn impuation
library(pROC)     # plot ROC
library(ROSE)     # for oversampling
library(doSNOW)   # allow multicore
source("utilities.R")
cl <- makeCluster(3)
registerDoSNOW(cl)
# read data and split into train and test =====================================
# remember to remove duration
dat <- fread("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE) %>%
.[, duration := NULL]
set.seed(1234)
in_train <- createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
treat_cat <- function(data = dat_train){
# To treat categorical feature. The unknowns are treated as its own category
# as there are reasons to be missing.
#
# Arguments
# ---------
#   data: data frame with features to be preprocessed
#
# Return
# ------
#   A data frame with preproccessed features
# "unknown" and "yes" in "default combined as one group as only 3 "yes"
data[default %in% c("unknown", "yes"), default := "TBD"]
# create a new categorical feature for those age > 60
data[age > 60, over_60 := "yes"]
data[age <= 60, over_60 := "no"]
data[, over_60 := factor(over_60)]
# pdays into categorical feature pcontact of two groups
data[pdays == 999, pcontact := "no"]
data[pdays != 999, pcontact := "yes"]
data[, pcontact := factor(pcontact) ]
data[, pdays := NULL]
# loan not important
data[, loan := NULL]
return(data)
}
treat_num <- function(data_train, data_new = NULL){
# fix skewness
if (is.null(data_new)){
data_new <- data_train
}
preproc <- preProcess(data_train, method = c("BoxCox"))
data_new <- predict(preproc, data_new)
# remove not important features
data_new[, cons.conf.idx := NULL]
data_new[, nr.employed := NULL]
return(data_new)
}
dat_train <- treat_cat(dat_train)
dat_train <- treat_num(dat_train)
dat_test <- treat_cat(dat_test)
dat_test <- treat_num(dat_train, dat_test)
# random forest model =================================================
# overfitting
rf <- randomForest(y ~ ., dat_train)
rf_pred_train <- predict(rf, dat_train, type = "prob")[, 2]
rf_roc_train <- roc(dat_train$y, rf_pred_train)
rf_pred_test <- predict(rf, dat_test, type = "prob")[, 2]
rf_roc_test <- roc(dat_test$y, rf_pred_test)
plot_rocs(`rf train` = rf_roc_train, `rf test` = rf_roc_test)
predict(rf, dat_train, type = "prob")
# read data and split into train and test =====================================
# remember to remove duration
dat <- fread("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE) %>%
.[, duration := NULL]
set.seed(1234)
in_train <- createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
treat_cat <- function(data = dat_train){
# To treat categorical feature. The unknowns are treated as its own category
# as there are reasons to be missing.
#
# Arguments
# ---------
#   data: data frame with features to be preprocessed
#
# Return
# ------
#   A data frame with preproccessed features
# "unknown" and "yes" in "default combined as one group as only 3 "yes"
data[default %in% c("unknown", "yes"), default := "TBD"]
# create a new categorical feature for those age > 60
data[age > 60, over_60 := "yes"]
data[age <= 60, over_60 := "no"]
data[, over_60 := factor(over_60)]
# pdays into categorical feature pcontact of two groups
data[pdays == 999, pcontact := "no"]
data[pdays != 999, pcontact := "yes"]
data[, pcontact := factor(pcontact) ]
data[, pdays := NULL]
# loan not important
data[, loan := NULL]
return(data)
}
treat_num <- function(data_train, data_new = NULL){
# fix skewness
if (is.null(data_new)){
data_new <- data_train
}
preproc <- preProcess(data_train, method = c("BoxCox"))
data_new <- predict(preproc, data_new)
# remove not important features
data_new[, cons.conf.idx := NULL]
data_new[, nr.employed := NULL]
return(data_new)
}
dat_train <- treat_cat(dat_train)
dat_train <- treat_num(dat_train)
dat_test <- treat_cat(dat_test)
dat_test <- treat_num(dat_train, dat_test)
# over-sampling train data
dat_os <- ovun.sample(
y ~.,
data = dat_train,
method = "over",
seed = 4321
)$data
# logistic regression again ===================================================
lr <- glm(y ~ ., data = dat_os, family = binomial)
lr_pred_train <- predict(lr, dat_train, type = "response")
lr_roc_train <- roc(dat_train$y, lr_pred_train)
lr_pred_test <- predict(lr, dat_test, type = "response")
lr_roc_test <- roc(dat_test$y, lr_pred_test)
# plot roc curves using train and test data
plot_rocs(`logit train` = lr_roc_train, `logit test` = lr_roc_test)
# random forest model =================================================
# overfitting
rf <- randomForest(y ~ ., dat_os)
rf_pred_train <- predict(rf, dat_train, type = "prob")[, 2]
rf_roc_train <- roc(dat_train$y, rf_pred_train)
rf_pred_test <- predict(rf, dat_test, type = "prob")[, 2]
rf_roc_test <- roc(dat_test$y, rf_pred_test)
plot_rocs(`rf train` = rf_roc_train, `rf test` = rf_roc_test)
str(dat_train)
hist(dat_train$age)
hist(dat_test$age)
mean(dat_train$age)
mean(dat_test$age)
mean(dat_test$campaign)
mean(dat_train$campaign)
# read data and split into train and test =====================================
# remember to remove duration
dat <- fread("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE) %>%
.[, duration := NULL]
set.seed(1234)
in_train <- createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
mean(dat_train$campaign)
mean(dat_test$campaign)
mean(dat_test$age)
mean(dat_train$age)
# read data and split into train and test =====================================
# remember to remove duration
dat <- fread("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE) %>%
.[, duration := NULL]
set.seed(1234)
in_train <- createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
treat_cat <- function(data = dat_train){
# To treat categorical feature. The unknowns are treated as its own category
# as there are reasons to be missing.
#
# Arguments
# ---------
#   data: data frame with features to be preprocessed
#
# Return
# ------
#   A data frame with preproccessed features
# "unknown" and "yes" in "default combined as one group as only 3 "yes"
data[default %in% c("unknown", "yes"), default := "TBD"]
# create a new categorical feature for those age > 60
data[age > 60, over_60 := "yes"]
data[age <= 60, over_60 := "no"]
data[, over_60 := factor(over_60)]
# pdays into categorical feature pcontact of two groups
data[pdays == 999, pcontact := "no"]
data[pdays != 999, pcontact := "yes"]
data[, pcontact := factor(pcontact) ]
data[, pdays := NULL]
# loan not important
data[, loan := NULL]
return(data)
}
treat_num <- function(data_train, data_new = NULL){
# fix skewness
if (is.null(data_new)){
data_new <- data_train
}
preproc <- preProcess(data_train, method = c("center", "scale", "BoxCox"))
data_new <- predict(preproc, data_new)
# remove not important features
data_new[, cons.conf.idx := NULL]
data_new[, nr.employed := NULL]
return(data_new)
}
dat_train <- treat_cat(dat_train)
mean(dat_train$age)
dat_train <- treat_num(dat_train)
mean(dat_train$age)
hist(dat_train$age)
dat_test <- treat_cat(dat_test)
dat_test <- treat_num(dat_train, dat_test)
hist(dat_test$age, add = T, col = "red")
hist(dat_test$age)
library(data.table)
library(magrittr)
library(caret)
library(randomForest)
library(RANN)     # for knn impuation
library(pROC)     # plot ROC
library(ROSE)     # for oversampling
library(doSNOW)   # allow multicore
source("utilities.R")
cl <- makeCluster(3)
registerDoSNOW(cl)
# read data and split into train and test =====================================
# remember to remove duration
dat <- fread("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE) %>%
.[, duration := NULL]
set.seed(1234)
in_train <- createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
clean_data <- function(data = dat_train){
# To treat categorical feature. The unknowns are treated as its own category
# as there are reasons to be missing.
#
# Arguments
# ---------
#   data: data frame with features to be preprocessed
#
# Return
# ------
#   A data frame with preproccessed features
# "unknown" and "yes" in "default combined as one group as only 3 "yes"
data[default %in% c("unknown", "yes"), default := "TBD"]
# create a new categorical feature for those age > 60
data[age > 60, over_60 := "yes"]
data[age <= 60, over_60 := "no"]
data[, over_60 := factor(over_60)]
# pdays into categorical feature pcontact of two groups
data[pdays == 999, pcontact := "no"]
data[pdays != 999, pcontact := "yes"]
data[, pcontact := factor(pcontact) ]
data[, pdays := NULL]
# loan not important
data[, loan := NULL]
data[, cons.conf.idx := NULL]
data[, nr.employed := NULL]
return(data)
}
pre_proc <- preProcess(data_train, method = c("center", "scale", "BoxCox"))
pre_proc <- preProcess(dat_train, method = c("center", "scale", "BoxCox"))
dat_train <- clean_data(dat_train)
dat_train <- predict(pre_proc, dat_train)
# read data and split into train and test =====================================
# remember to remove duration
dat <- fread("bank-additional/bank-additional-full.csv",
stringsAsFactors = TRUE) %>%
.[, duration := NULL]
set.seed(1234)
in_train <- createDataPartition(dat$y, p = 0.8, list = FALSE)
dat_train <- dat[in_train,]
dat_test <- dat[-in_train,]
clean_data <- function(data = dat_train){
# To treat categorical feature. The unknowns are treated as its own category
# as there are reasons to be missing.
#
# Arguments
# ---------
#   data: data frame with features to be preprocessed
#
# Return
# ------
#   A data frame with preproccessed features
# "unknown" and "yes" in "default combined as one group as only 3 "yes"
data[default %in% c("unknown", "yes"), default := "TBD"]
# create a new categorical feature for those age > 60
data[age > 60, over_60 := "yes"]
data[age <= 60, over_60 := "no"]
data[, over_60 := factor(over_60)]
# pdays into categorical feature pcontact of two groups
data[pdays == 999, pcontact := "no"]
data[pdays != 999, pcontact := "yes"]
data[, pcontact := factor(pcontact) ]
data[, pdays := NULL]
# loan not important
data[, loan := NULL]
data[, cons.conf.idx := NULL]
data[, nr.employed := NULL]
return(data)
}
dat_train <- clean_data(dat_train)
dat_test <- clean_data(dat_test)
pre_proc <- preProcess(dat_train, method = c("center", "scale", "BoxCox"))
dat_train <- predict(pre_proc, dat_train)
dat_test <- predict(pre_proc, dat_test)
# over-sampling train data
dat_os <- ovun.sample(
y ~.,
data = dat_train,
method = "over",
seed = 4321
)$data
# logistic regression again ===================================================
lr <- glm(y ~ ., data = dat_os, family = binomial)
lr_pred_train <- predict(lr, dat_train, type = "response")
lr_roc_train <- roc(dat_train$y, lr_pred_train)
lr_pred_test <- predict(lr, dat_test, type = "response")
lr_roc_test <- roc(dat_test$y, lr_pred_test)
# plot roc curves using train and test data
plot_rocs(`logit train` = lr_roc_train, `logit test` = lr_roc_test)
# random forest model =================================================
# overfitting
rf <- randomForest(y ~ ., dat_os)
rf_pred_train <- predict(rf, dat_train, type = "prob")[, 2]
rf_roc_train <- roc(dat_train$y, rf_pred_train)
rf_pred_test <- predict(rf, dat_test, type = "prob")[, 2]
rf_roc_test <- roc(dat_test$y, rf_pred_test)
plot_rocs(`rf train` = rf_roc_train, `rf test` = rf_roc_test)
mean(dat_train$age)
mean(dat_test$age)
mean(dat_test$campaign)
mean(dat_train$campaign)
hist(dat_test$age)
library(e1071)
# support vector machine ======================================================
svm <- svm(y ~ ., dat_os)
